{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "buzf8i95QAP5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to a range of 0 to 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# One-hot encode the target labels\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeWuf0R6QTio",
        "outputId": "5a76e05d-d324-4689-8188-1f2e6f4049dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))  # Flatten the 28x28 images into a 1D array\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))  # Output layer with 10 units for each digit\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Sr4O87b1Qkd3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model*\n",
        "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "g-8P75HgQqF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data*\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-nE50FkRqOu",
        "outputId": "407651d9-2ee5-48b4-a37c-a1a2546f06f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9796\n",
            "Test accuracy: 0.9796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose some random test images*\n",
        "num_samples = 10\n",
        "\n",
        "sample_indices = np.random.randint(0, x_test.shape[0], num_samples)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(x_test[sample_indices])\n",
        "\n",
        "# Display the results\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    plt.imshow(x_test[idx], cmap='gray')\n",
        "    plt.title(f\"True label: {np.argmax(y_test[idx])}, Predicted label: {np.argmax(predictions[i])}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "hq37q_m6RqWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9RQom6lRqY-",
        "outputId": "b1e55c3a-4146-47b4-e786-3d0f96e4497d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have trained and compiled your model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Save the model to Colab's temporary directory\n",
        "model.save('10_EPOCH_trained_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCMk7ffxRqbg",
        "outputId": "7409102f-c172-4b6f-e789-d01eb4ac5039"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2772 - accuracy: 0.9205 - val_loss: 0.1369 - val_accuracy: 0.9618\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1250 - accuracy: 0.9628 - val_loss: 0.0918 - val_accuracy: 0.9738\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0855 - accuracy: 0.9737 - val_loss: 0.0853 - val_accuracy: 0.9730\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0626 - accuracy: 0.9812 - val_loss: 0.0751 - val_accuracy: 0.9760\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0483 - accuracy: 0.9850 - val_loss: 0.0868 - val_accuracy: 0.9758\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0383 - accuracy: 0.9882 - val_loss: 0.0752 - val_accuracy: 0.9785\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.0789 - val_accuracy: 0.9772\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.0695 - val_accuracy: 0.9820\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0816 - val_accuracy: 0.9780\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0707 - val_accuracy: 0.9813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "temp_path = '/content/10_EPOCH_trained_model.h5'\n",
        "drive_path = '/content/drive/MyDrive/10_EPOCH_trained_model.h5'\n",
        "\n",
        "shutil.copy2(temp_path, drive_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6_EL_t1rRqd2",
        "outputId": "0285aaa6-0745-4652-ae2c-b6bf04c0c3a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/10_EPOCH_trained_model.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your model is saved in '/content/drive/MyDrive/Newton-Digit-Recognition/trained_model.h5'\n",
        "model_path = '/content/10_EPOCH_trained_model.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n"
      ],
      "metadata": {
        "id": "yFRF20t_YLZ1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *\n",
        "\n",
        "!pip install -U -q PyDrive"
      ],
      "metadata": {
        "id": "dIatWcnIYLcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *\n",
        "from google.colab import auth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "\n",
        "# Authenticate with Google Drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleDrive(gauth)\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "metadata": {
        "id": "2lNtId0HYLeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Folder path where the images are located\n",
        "folder_path = '/content/drive/MyDrive/Newton-Digit-Recognition'\n",
        "\n",
        "# List all files in the folder\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# Filter the files to select only image files (you can add more image extensions if needed)\n",
        "image_extensions = ['.jpg', '.jpeg', '.png']\n",
        "image_files = [file for file in file_list if os.path.splitext(file)[1].lower() in image_extensions]\n",
        "\n",
        "# Load and preprocess the images\n",
        "images = []\n",
        "for image_file in image_files:\n",
        "    # Load the image without reducing the image quality\n",
        "    image_path = os.path.join(folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('L')\n",
        "\n",
        "    # Resize the image to match the input shape of your model (28x28)\n",
        "    image = image.resize((28, 28))\n",
        "\n",
        "    image_array = np.array(image) / 255.0\n",
        "    image_array = image_array.reshape(1, 28, 28)\n",
        "    images.append(image_array)\n",
        "\n",
        "# Visualize the images (optional)\n",
        "for image_array in images:\n",
        "    plt.imshow(image_array[0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "BZB69pRqaKnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you've already loaded your trained model *\n",
        "# model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Make predictions and visualize the results\n",
        "for i, image_array in enumerate(images):\n",
        "    prediction = model.predict(image_array)\n",
        "    predicted_label = np.argmax(prediction[0])\n",
        "\n",
        "    plt.imshow(image_array[0], cmap='gray')\n",
        "    plt.title(f\"Predicted label: {predicted_label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IEwaqrk-aKkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the single image you want to test\n",
        "single_image_path = '/content/drive/MyDrive/sample_image.png'  # Replace with the actual path\n",
        "\n",
        "# Load the image\n",
        "image = Image.open(single_image_path).convert('L')\n",
        "\n",
        "# Resize the image to match the input shape of your model (28x28)\n",
        "image = image.resize((28, 28))\n",
        "\n",
        "# Preprocess the image\n",
        "image_array = np.array(image) / 255.0\n",
        "image_array = image_array.reshape(1, 28, 28)\n",
        "\n",
        "# Visualize the image (optional)\n",
        "plt.imshow(image_array[0], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4IDhXlZsaKiP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "8b2df73c-41ef-4267-a145-d36f7c8b3ffa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJsUlEQVR4nO3csWvVZx/G4eeY5DgkxlIQFApSsRSCtkWKHSS4uzgVhHZxEjeH0qX/goK4FYWOTl1aRFDq0kHBQXRQK1ZQcaii0ZjW6kly3uXlhncy3594zBuvaz73+YUkJ588y9MbDofDBgCttXXv+gsAYPUQBQBCFAAIUQAgRAGAEAUAQhQACFEAIMZX+sLJycnymy8uLpY3ALxel7/JT548ee1rnBQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAYsUX4r169ar85i7EA3g7JiYm3sr7OikAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxIovxOv1em/z6wCg4G39TXZSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACI8Xf9BbwPxsfr3+Z+v9/pWcPhsLxZXl4ubwaDwUieA4yWkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAuBCvaGJiorzZv3//SDattfbvv/+WN0+fPi1vLly4UN48ePCgvGmttbt375Y3Lt8braWlpfLm5cuXI3sWK+ekAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAED0hsPhcCUv7Pf75TcfDAblzWo3PT1d3vz888/lzVdffVXetDa6GyS7/GyfP3/e6Vl37twpbxYXF8ubdevW3v9IK/x4/48uN8z++eef5c1PP/1U3rTW2pUrV8qbLt+H1W5qaqq8WclncO19CgDoTBQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAGH/XX8D/mxcvXpQ3J06cKG8+/fTT8qa11v7666/y5qOPPipvdu7cWd7s2rWrvGmttS+++KK8efz4cXmzadOm8mZsbKy86Xo526tXr8qb+fn58mbr1q3lTZcLHO/fv1/etNbatWvXypsuFyS+r5wUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAMKFeEWDwaC8OXv2bHlz/vz58qa11paWlsqb8fH6r0G/3y9vNm/eXN601trHH39c3ty7d6+8+eSTT8qbLt+75eXl8qa11hYWFkbyrNOnT5c3XX4fHj16VN601v1CQVbGSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgXIg3AouLiyPZdNXlkr8XL16UN8+ePStvWmvt9u3b5U2XiwFv3bpV3vR6vfKm64VuExMT5c2BAwfKm/Xr15c3ly9fLm9+++238qa1bj9bVs5JAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwSyqr3qhuxRzlzbRdbN++vbz5/vvvy5su34dTp06VNw8ePChvePucFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDChXgwYtPT051233zzTXmzbdu28ubmzZvlzfXr18ubUV10SI2TAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4EA/ewNjYWHmzZ8+eTs86dOhQefPs2bPy5ocffihvbty4Ud6wOjkpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQL8eANrF+/vrzZu3dvp2dNTU2VN2fOnClvfv/99/JmMBiUN6xOTgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA4UI8eAObNm0qb2ZnZzs9a25urrw5depUeTM/P1/esHY4KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQbkmF/9qwYUN5c/DgwfJmZmamvGmttXPnzpU3Fy9eLG+Gw2F5w9rhpABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQLsRjTRofr/9q79u3r7w5fPhweTM3N1fetNbayZMny5uFhYVOz+L95aQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEC7EY9Xr9Xrlzfbt28ub7777rrz54IMPyptffvmlvGmttYsXL5Y3y8vLnZ7F+8tJAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBciMeq9+GHH5Y3x44dK28+//zz8ubq1avlzY8//ljetNba33//3WkHFU4KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFCPEZm3bpu/4Ps2LGjvJmdnS1v5ubmypujR4+WN10u0YNRcVIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAINySysjMzMx02nW5ibTX65U3x48fL29+/fXX8mYwGJQ3MCpOCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDhQjw6mZycLG++/vrrTs/67LPPypt//vmnvLl06dJIngOrmZMCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQLgQjzY2Nlbe7N69u7z59ttvy5vWWuv3++XNwsJCeTMYDMqbXq9X3gyHw/IGRsVJAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBciEebmJgob7788svyZsuWLeVNa60tLy+XN3/88Ud5Mz8/X9643I61xkkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgHBLKp10ubn08ePHnZ518+bN8ubIkSPlza1bt8obWGucFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQCiNxwOhyt5Yb/fL7/5YDAobxi9Xq9X3kxPT5c3GzduLG9aa+3ly5flzcOHD8ubFX4UYFWYmpoqb54/f/7a1zgpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMSKL8QDYO1zUgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACD+Aw3Wce9sogLIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you've already loaded your trained model\n",
        "# model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(image_array)\n",
        "predicted_label = np.argmax(prediction[0])\n",
        "\n",
        "print(f\"Predicted label: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIQk0MTfaKfo",
        "outputId": "7b891f21-e1d2-49a5-fdf9-fefb2a477f32"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicted label: 7\n"
          ]
        }
      ]
    }
  ]
}